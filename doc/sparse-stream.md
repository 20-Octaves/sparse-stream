# Sparse Stream

This document describes the [**Sparse Stream**](../README.md) format.

## Motivation

Sparse Stream is a meta format that emerged from our efforts to formalize, simplify, and improve a low-level streaming protocol used in a research/dev setting for capturing the output of generators of high-resoloution, high-dimensinality, sparse acoustic features.

We needed a format for streaming acoustic features that would be simple, space efficient, supporting sparse, high-dimensional features, generated by multiple, simultaneous high-resolution acoustic-analysis alogrithms, and agnostic about the details of the set of algorithms being used to generate features.

## Meta format

Sparse Stream is a meta format that defines a simple structure for concrete implementations to follow when producing features derived from an audio (stream) input.

The format supports high-resolution acoustic-feature generators for which the features are may be emitted asynchronously and at a higher rate than the audio frame-rate samplerate.

The Sparse Stream format aims to be relatively un-opinionated about how an implementation encodes the features it represents.
It provides a simple, tiered framework that addresses some fundamental constraints of temporally-based acoustic-feature streams:
- The range and precision of the temporal index of data and features (timestamp) in a stream can be very large, e.g. from microseconds to weeks.  The format supports factoring of such timestamps.
- Generators of high-resolution features can asynchronously emit numerous features for each audio frame.  The format tiers support this low-level requirement.
- The flow of data in a stream may occasionally be interupted and unknown amounts of data may be lost before the underlying transport recovers and the flow of data resumes -- and the stream producer may be unaware of the data loss.  The format supports straightforward reframing to recover from such damage to the stream.

The format is somewhat biased about being close to the source of audio data.
As such, it readily accommodates audio that has a single, fixed samplerate, a fixed number of audio channels, and frames which interleave the samples from each channel.

Overall there is an implicit bias towards front-end devices with microphones (on the edge, and with computes and bandwidth to spare) doing some relatively expensive up-front application-specific computation, and either using the feature stream directly or sending it to more central services.

### Notation

For readability of large numbers in the examples, we adopt the use of underscores in numeric literals, as do [many modern programming languages](https://peps.python.org/pep-0515/#prior-art).
E.g. one thousand as `1_000`, and two raised to the twentieth power as `1_048_576`.


## Events

A Sparse Stream encodes a sequence of features, where each feature is a single "point" in a (potentially large) multi-dimensional acoustic-feature space.
These analysis dimensions typically correspond directly to feature detectors and their outputs.

### Concrete example
Consider 2-channel audio being processed by a frontend that has 7 different types of detectors (feature generators).
One detector type (number 5) indicates the discretized energy output of a set of 50 filters.
At frame 19_364 for the left audio channel, detector type 5, filter number 23 is detecting a level of 47.
The feature point is represented by the tuple `(19_364, 0, 5, 23, 47)`.

Based on the details of the generator and the audio input, the dimensions of detector type, energy, filter number, and audio channel would each have a well-defined set of index values.
For instance, there might be 2 audio channels, and the front end has 7 detector types, and detector type 5 has 100 distinct energy values, and an array of 50 such filters.
The overall size of the space in which this point appears might be `(65_536, 2, 7, 50, 100)`.

In general, for a given feature generator, the set of analysis dimensions and the number of indices in each dimension are configuration parameters of the generator.
The set of dimensions is small and fixed for the duration of the stream.
And, except for the temporal dimension, the number of indices in each dimension is relatively small.
E.g. a typical generator may have 5 detection algorithms, each generating 3 feature values when triggered, with values between 0 and 63, arranged in an array of 1_600 detectors, and processing 2 audio channels  -- so, a 3_024_000 dimensional space (not including the temporal index)

### The unbounded dimension

One dimension of such feature events represents a "temporal" index, e.g. the frame number of the audio samples.
As such, the index for this temporal dimension monotonically increases with the stream's events and this distinguished dimension gets special (opinionated) consideration in the Sparse Stream format.

## Syntax

A Sparse Stream is a sequence of terminal objects.
The "syntax" of the objects in the stream provides three tiers for the events, whereby an inner object implicitly includes all the values of the outer objects.

We use an [EBNF-based](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form) description of the syntax of the abstract objects in a stream.

### Terminals

There are five abstract terminals:
- SENTINEL -- used to start a stream, and used for "heartbeat" to support re-alignment and resume on streams that may have uncontrolled, unrecoverable gaps, e.g. due to an unreliable data link
- CONFIG -- configuration information about the structure of the acoustic-feature points (types, dimensions, sizes) and about the audio input
- MOMENT -- supports large-scale increments of the distinguished temporal index and related bookkeeping
- TICK -- fine-grained incrementes of the temporal index, e.g audio frame, audio channel, and sample
- FEATURE -- details for the outputs of a detector
- END -- end of stream

The details of the semantics and represetnation of these terminals depends upon the particular implementation.
One possible pattern is to use fixed size objects, e.g. 8 bytes each, where the value of the first byte indicates the terminal type, and the remaining bytes encode the "value" of the terminal.
Another pattern would be to use JSON objects, each with a type attribute.
Using JSON would does not align with the space and time efficiency goals of Sparse Stream, but can be useful for development debugging.

### Language

The Sparse Stream language rules specify a stream as a sequence of nested containments:

```
stream = 1* extent , END .
extent  = SENTINEL , 1* CONFIG , * moment .
moment = MOMENT , *  tick .
tick   = TICK , * FEATURE .
```

E.g. a terminal stream, with indentation to illustrate the containment structure:

```
SENTINEL CONFIG CONFIG
  MOMENT
    TICK
      FEATURE
      FEATURE
    TICK
    TICK
      FEATURE
  MOMENT
    TICK
      FEATURE
      FEATURE
SENTINEL CONFIG CONFIG
  MOMENT
  MOMENT
    TICK
      FEATURE
      FEATURE
END
```

In practice, for a high-resolution generator, each TICK will correspond to a single audio sample, and dozens of FEATURE are typically emitted for each TICK, and thousands of TICKs appear in each MOMENT.
The generation of multiple FEATURE points for each TICK sample means that the resulting stream will be (much) larger than the audio input.

## Concrete implementation

#### **`Octv, version 1`**

Here are essential details of a C language implementation that conforms to the Sparse Stream meta specification.
While detailed, and actually implemented at some point, the [examples below](#examples) are non-normative.

Each terminal is an 8 byte structure, and the first byte of the struct indicates the terminal type.
The remaining bytes provide the value for the terminal.
A union of all terminal structs (payload), with an anoymous type field, is used for writing and reading.
Upon read, the anonymous type field is used for casting and dispatch to the logic for the specific terminal type.

Except where otherwise noted, the descriptions of the terminals are specific to version 1 of Octv.

### SENTINEL and END

```
// SENTINEL and END
typedef struct {
  char type;
  char chars[3];
  uint8_t signature[4];
} OctvDelimiter;
```

The SENTINEL type is 79 (0x4f), the character code of "O".
The SENTINEL terminal is fixed -- all 8 bytes are specified and will be the same for all versions of Octv.
```
static const OctvDelimiter octv_sentinel = { 'O', 'c', 't', 'v', 0xa4, 0x6d, 0xae, 0xb6 };
```

The END type is 69 (0x45), the character code of "E".
All 8 bytes of the END terminal are specified:
```
static const OctvDelimiter octv_end = { 'E', 'n', 'd', ' ', 0xa4, 0x6d, 0xae, 0xb6 };
```

Note that SENTINEL and END have the same signature field.


### CONFIG

```
// CONFIG
typedef struct {
  uint8_t type;
  uint8_t octv_version;

  uint8_t num_audio_channels;
  // 24-bit sample rate in Hz, little endian
  uint8_t audio_sample_rate_0;
  uint8_t audio_sample_rate_1;
  uint8_t audio_sample_rate_2;

  uint16_t num_detectors;
} OctvConfig;
```

The CONFIG type is 0x50.  The `version` is 1 in the examples here.

E.g.
```
int samplerate = 48000;
OctvConfig config = { 0x50, 1,
                      2,
                      samplerate & 0xff, (samplerate >> 8) & 0xff, (samplerate >> 16) & 0xff,
                      1440 };
```


For all versions of Octv, a CONFIG of type 1 is always required immediately following the SENTINEL.

The intent is that future versions of the concrete Octv format will always have the same SENTINEL (and END) terminals, and the version field of the CONFIG terminal will be used to dispatch to version-specific logic for the stream.


#### Audio

The `num_audio_channels` field specifies how many channels of concurrent audio are represented in the stream, typically between 1 and 4.
For version 1, the 24-bit `audio_sample_rate` integer encodes samplerate of the stream in Hz.

#### Feature generators

The `num_detectors` field indicates the largest size of the sets of detectors implemented in the system, e.g. a maximum array size of 1_440 configured detection modules.
The value of `detector_index` in `OctvFeature` will always be smaller than `num_detectors`.


### MOMENT
```
// MOMENT
typedef struct {
  uint8_t type;
  uint8_t _reserved[3];

  uint32_t audio_frame_index_hi_bytes;
} OctvMoment;
```
The MOMENT type is 0x60.

Version 1 of Octv uses 48 bits for the index of the distinguished, temporal dimension.
In practice, we have worked with streams of up to several days duration, but rarely more than a week.

The `audio_frame_index_hi_bytes` field is the high-order 32 bits of the 48-bit frame counter.
This terminal is emitted whenever the lowest 16 bits of the frame counter are 0.
E.g. for a generator of an Octv stream, at the start of work on each frame:
```
++frame_counter;
if (!(frame_counter & ((1 << 16) - 1))) {
   OctvMoment moment = { 0x60, 0, 0, 0, frame_counter >> 16 };
   emit(&moment);
}
```

For a 48_000 Hz signal a MOMENT terminal is emitted every 1.365 seconds.

### TICK
```
// TICK
typedef struct {
  uint8_t type;

  uint8_t audio_channel;
  uint16_t audio_frame_index_lo_bytes;
  float audio_sample;
} OctvTick;
```

The TICK type is 0x70.

The TICK terminal indicates that features will be emitted for the `audio_sample` at frame `audio_frame_index_lo_bytes`, channel `audio_channel`.
The `float` sample is typically in the range of 1.0 to -1.0.
Note that the full frame index is given by:
```
int frame_index = (moment.audio_frame_index_hi_bytes << 16) | tick.audio_frame_index_lo_bytes;
```

### FEATURE
```
// FEATURE terminal has multiple "values" based on the value in type which has top two bits 0 and
// at least one non-zero bit in low 6 bits
typedef struct {
  uint8_t type;

  uint8_t frame_offset;
  uint16_t detector_index;

  union {
    struct {
      // type: range(OCTV_FEATURE_0_LOWER, OCTV_FEATURE_0_UPPER)
      int8_t level_0_int8_0;
      int8_t level_0_int8_1;
      int8_t level_0_int8_2;
      int8_t level_0_int8_3;
    };
    struct {
      // type: range(OCTV_FEATURE_2_LOWER, OCTV_FEATURE_2_UPPER)
      int8_t level_2_int8_0;
      int8_t level_2_int8_1;
      int16_t level_2_int16_0;
    };
    struct {
      // type: range(OCTV_FEATURE_3_LOWER, OCTV_FEATURE_3_UPPER)
      int16_t level_3_int16_0;
      int16_t level_3_int16_1;
    };
  };
} OctvFeature;
} OctvFeature;
```

The FEATURE type can be one of 63 values.
There are three ranges, and the value is within the range that indicates which of the anonymous structs is valid:
```
// these are half-open ranges (UPPER is not in the range)
// 31 use level_0_* anonymous struct fields
#define OCTV_FEATURE_0_LOWER  0x01
#define OCTV_FEATURE_0_UPPER  0x20
// 16 use level_2_* anonymous struct fields
#define OCTV_FEATURE_2_LOWER  0x20
#define OCTV_FEATURE_2_UPPER  0x30
// 16 use level_3_* anonymous struct fields
#define OCTV_FEATURE_3_LOWER  0x30
#define OCTV_FEATURE_3_UPPER  0x40
```
The specific value indicates which detector has generated the FEATURE terminal, and thus the semantics of the levels.

For instance, type `0x03` indicates a detector that populates the four `level_0_int8_*` fields, and type `0x30` indicates a detector that populates the two `level_3_int16_*` fields.

In short, each FEATURE `type` indicates a particular feature-generating algorithm and the class of its output values.

The `detector_index` indicates which of the array detectors (implementing the indicated algorithm) has generated the feature.

In practice to date the values have ranged from -31 to +31 for most feature types.
And only rarely does an algorithm use all four slots.
Also, we have fewer algorithms that need one or two 16-bit values, so there fewer range slots for these types.

For high-resolution features, the `frame_offset` encodes a fractional measure of the frame duration (e.g. how many sixteenths), indicating when, between the previous and current frames, the feature was observed.

The details behind  `type`, `frame_offset`, `detector_index`, and `level_*` depend on the detectors and their configuration.
The ranges for the FEATURE type value permit low-level parsing (and display) logic to work regardless of the details of the alogrithms being developed.

> In some ways these details are irrelevant due to the ubiquitous use of machine learning to discover patterns in sets of features and to assess feature importance scores -- that is, the importance of these details will depend on the application being learned rather than any details and descriptions of the semantics.

## Examples

> This section is a WIP while the code interfaces get settled.

The 64-byte binary file [`src/test2.octv`](../src/test2.octv) contains an instance of each TERMINAL type.
They are ordered as a valid Sparse Stream instance.
When parsed to Python objects that render to JSON, the following (vebose) sequence is emitted:
```
{"type_name": "OctvSentinel", "type": "0x4f", "payload": "4f_63_74_76_a4_6d_ae_b6"}
{"type_name": "OctvConfig", "type": "0x50", "payload": "50_01_02_80_bb_00_58_02", "octv_version": 1, "audio_sample_rate": 48000, "num_detectors": 600}
{"type_name": "OctvMoment", "type": "0x60", "payload": "60_00_00_00_02_00_00_00", "audio_frame_index_hi_bytes": 131072}
{"type_name": "OctvTick", "type": "0x70", "payload": "70_01_01_02_00_00_40_3f", "audio_channel": 1, "audio_frame_index_lo_bytes": 513, "audio_sample": 0.75}
{"type_name": "OctvFeature", "type": "0x3", "payload": "03_0f_01_02_01_02_04_08", "frame_offset": 15, "detector_index": 513, "level_0_int8_0": 1, "level_0_int8_1": 2, "level_0_int8_2": 4, "level_0_int8_3": 8}
{"type_name": "OctvFeature", "type": "0x23", "payload": "23_0f_01_02_01_02_04_08", "frame_offset": 15, "detector_index": 513, "level_2_int8_0": 1, "level_2_int8_1": 2, "level_2_int16_0": 2052}
{"type_name": "OctvFeature", "type": "0x33", "payload": "33_0f_01_02_01_02_04_08", "frame_offset": 15, "detector_index": 513, "level_3_int16_0": 513, "level_3_int16_1": 2052}
{"type_name": "OctvEnd", "type": "0x45", "payload": "45_6e_64_20_a4_6d_ae_b6"}
```
